name: Build and Deploy

on:
  push:
    branches: [ main ]
    paths-ignore:
      - '**.md'
      - '.gitignore'
      - '.cursorrules'
      - 'LICENSE'

env:
  INSTANCE_DIR: /var/lib/virga-plateform/instances
  BACKUP_DIR: /var/lib/virga-plateform/backups
  BUILD_METADATA_DIR: /var/lib/virga-plateform/build-metadata
  DOCKER_REGISTRY: rehanalimahomed/virga-plateform
  COMPANY_DOMAIN: amadiy.com
  PROXY_USER: amadiyadm
  PROXY_HOST: ${{ secrets.PROXY_HOST }}
  PROXY_MANAGER_DIR: /home/amadiyadm/proxy-settings
  APP_SERVER_IP: ${{ secrets.DOCKERS_HOST }}

jobs:
  initialize:
    name: 🔧 Initialize and List Instances
    runs-on: self-hosted
    outputs:
      version: ${{ steps.version.outputs.version }}
      display_version: ${{ steps.version.outputs.display_version }}
      active_instances: ${{ steps.list-instances.outputs.instances }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      with:
        clean: true
        fetch-depth: 0
        
    - name: Check Environment
      run: |
        echo "🔍 Checking environment configuration..."
        echo "Instance Directory: $INSTANCE_DIR"
        echo "Backup Directory: $BACKUP_DIR"
        echo "Current User: $(whoami)"
        echo "Docker Status: $(docker info | grep 'Server Version')"
        
        # Verify directories exist
        for dir in "$INSTANCE_DIR" "$BACKUP_DIR"; do
          if [ ! -d "$dir" ]; then
            echo "Creating directory: $dir"
            mkdir -p "$dir" || sudo mkdir -p "$dir"
          fi
        done
        
        # Validate required environment variables
        required_vars=("PROXY_HOST" "APP_SERVER_IP" "PROXY_MANAGER_DIR" "PROXY_USER")
        for var in "${required_vars[@]}"; do
          if [ -z "${!var}" ]; then
            echo "::error::Required environment variable $var is not set"
            exit 1
          fi
        done
        
        # Check Docker login status
        if ! docker info | grep -q "Username"; then
          echo "::warning::Docker Hub login not found. Will need to login during workflow."
          echo "NEED_DOCKER_LOGIN=true" >> $GITHUB_ENV
        else
          echo "✅ Docker Hub already logged in"
          echo "NEED_DOCKER_LOGIN=false" >> $GITHUB_ENV
        fi

    - name: Generate Version
      id: version
      run: |
        # Get base version from file
        BASE_VERSION=$(cat VERSION)
        BUILD_DATE=$(date +'%Y.%m.%d')
        GIT_SHORT_SHA=$(git rev-parse --short HEAD)
        BUILD_NUMBER=$(git rev-list --count HEAD)
        
        # Generate versions
        TECHNICAL_VERSION="${BASE_VERSION}-${BUILD_NUMBER}-${GIT_SHORT_SHA}"
        DISPLAY_VERSION="${BASE_VERSION} (${BUILD_DATE} build ${BUILD_NUMBER})"
        
        # Export versions
        echo "version=${TECHNICAL_VERSION}" >> $GITHUB_OUTPUT
        echo "display_version=${DISPLAY_VERSION}" >> $GITHUB_OUTPUT
        
        # Save to .env
        cat > .env << EOL
        VERSION=${TECHNICAL_VERSION}
        DISPLAY_VERSION=${DISPLAY_VERSION}
        BUILD_DATE=${BUILD_DATE}
        GIT_SHA=${GIT_SHORT_SHA}
        BUILD_NUMBER=${BUILD_NUMBER}
        EOL

    - name: List Active Instances
      id: list-instances
      run: |
        # Create temporary file for instances
        instance_file="/tmp/active_instances.txt"
        > "$instance_file"
        
        # Find and store active instances
        while IFS= read -r dir; do
          instance_id=$(basename "$dir")
          
          # Skip test and preprod instances
          if [[ "$instance_id" != test-* ]] && [[ "$instance_id" != preprod-* ]]; then
            if [ -f "$dir/secrets.env" ]; then
              container_name="${instance_id}-plateform"
              
              # Check if instance is running
              if docker ps --format '{{.Names}}' | grep -q "^${container_name}$"; then
                # Read domain from secrets.env safely
                domain=$(grep "^DOMAIN=" "$dir/secrets.env" | cut -d'=' -f2 | tr -d '"' | tr -d "'" | tr -d ' ')
                if [ -n "$domain" ]; then
                  printf "%s|%s|%s\n" "$instance_id" "$domain" "$dir" >> "$instance_file"
                fi
              fi
            fi
          fi
        done < <(find ${INSTANCE_DIR} -name "docker-compose.yml" -exec dirname {} \;)
        
        # Validate we found instances
        if [ ! -s "$instance_file" ]; then
          echo "::warning::No active instances found"
          echo "instances=" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        # Convert instances to a single line with proper escaping
        instances=$(cat "$instance_file" | tr '\n' ',' | sed 's/,$//')
        echo "instances=${instances}" >> $GITHUB_OUTPUT
        echo "Found active instances:"
        cat "$instance_file"

  build:
    name: 🏗️ Build and Test Code
    needs: [initialize]
    runs-on: self-hosted
    outputs:
      docker_image_built: ${{ steps.check-changes.outputs.docker_image_built }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      with:
        clean: true
        fetch-depth: 0

    - name: Check for Code Changes
      id: check-changes
      run: |
        # Ensure build metadata directory exists with proper permissions
        if [ ! -d "$BUILD_METADATA_DIR" ]; then
          echo "Creating build metadata directory..."
          mkdir -p "$BUILD_METADATA_DIR" || sudo mkdir -p "$BUILD_METADATA_DIR"
          sudo chown $(whoami) "$BUILD_METADATA_DIR"
          sudo chmod 755 "$BUILD_METADATA_DIR"
        fi
        
        # Get the last successful commit hash from permanent storage
        LAST_BUILD_FILE="${BUILD_METADATA_DIR}/last_successful_build"
        LAST_SUCCESSFUL_HASH=""
        
        if [ -f "$LAST_BUILD_FILE" ]; then
          LAST_SUCCESSFUL_HASH=$(cat "$LAST_BUILD_FILE")
        fi
        
        # If no last successful build found, consider everything changed
        if [ -z "$LAST_SUCCESSFUL_HASH" ]; then
          echo "No previous successful build found. Building Docker image."
          echo "docker_image_built=true" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        # Verify the hash exists in the repository
        if ! git rev-parse --quiet --verify "$LAST_SUCCESSFUL_HASH^{commit}" >/dev/null; then
          echo "Last successful build commit not found in history. Building Docker image."
          echo "docker_image_built=true" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        # Define patterns that should trigger a build
        BUILD_PATTERNS=(
          # Core application files
          "^src/"                    # Backend source code
          "^public/"                 # Frontend JavaScript
          "^app\.js$"                # Main application entry
          
          # Dependencies and build files
          "^package\.json$"          # NPM dependencies
          "^package-lock\.json$"     # NPM lock file
          "^Dockerfile$"             # Docker build instructions
          "^\.dockerignore$"         # Docker build exclusions
          
          # Configuration and views
          "^src/views/.*\.ejs$"     # View templates
          "^src/config/[^/]*\.js$"  # Config files (excluding subdirs)
          "^src/services/.*\.js$"   # Service files
          "^src/utils/.*\.js$"      # Utility files
        )
        
        # Define patterns to explicitly ignore
        IGNORE_PATTERNS=(
          "^\.github/"              # GitHub workflows
          "^__tests__/"             # Test files
          "^\.env.*$"               # Environment files
          "^VERSION$"               # Version file (handled by initialize job)
          "^.*\.md$"                # Documentation files
        )
        
        echo "Checking for changes in files..."
        NEEDS_BUILD=false
        
        # Get changed files using triple dot to include merge commits
        while IFS= read -r FILE; do
          [ -z "$FILE" ] && continue
          echo "Checking file: $FILE"
          
          # First check if file should be ignored
          SHOULD_IGNORE=false
          for PATTERN in "${IGNORE_PATTERNS[@]}"; do
            if echo "$FILE" | grep -qE "$PATTERN"; then
              echo "Ignoring file (matches ignore pattern): $FILE"
              SHOULD_IGNORE=true
              break
            fi
          done
          
          # Skip to next file if this one should be ignored
          if [ "$SHOULD_IGNORE" = true ]; then
            continue
          fi
          
          # Check if file matches any build pattern
          for PATTERN in "${BUILD_PATTERNS[@]}"; do
            if echo "$FILE" | grep -qE "$PATTERN"; then
              echo "Match found: $FILE matches build pattern $PATTERN"
              NEEDS_BUILD=true
              break 2
            fi
          done
        done < <(git diff --name-only "$LAST_SUCCESSFUL_HASH...HEAD")
        
        if [ "$NEEDS_BUILD" = true ]; then
          echo "Changes detected in relevant files. Building Docker image."
          echo "docker_image_built=true" >> $GITHUB_OUTPUT
        else
          echo "No relevant changes detected. Skipping Docker image build."
          echo "docker_image_built=false" >> $GITHUB_OUTPUT
        fi

    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '20'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
      
    - name: Run linting
      run: npm run lint
      
    - name: Run tests
      run: npm test
      
    - name: Build Docker image
      if: steps.check-changes.outputs.docker_image_built == 'true'
      run: |
        docker build -t ${DOCKER_REGISTRY}:${{ needs.initialize.outputs.version }} .
        docker tag ${DOCKER_REGISTRY}:${{ needs.initialize.outputs.version }} ${DOCKER_REGISTRY}:latest
      
    - name: Login to Docker Hub
      if: env.NEED_DOCKER_LOGIN == 'true' && steps.check-changes.outputs.docker_image_built == 'true'
      uses: docker/login-action@v2
      with:
        username: ${{ secrets.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_TOKEN }}
    
    - name: Push Docker image
      if: steps.check-changes.outputs.docker_image_built == 'true'
      run: |
        if ! docker push ${DOCKER_REGISTRY}:${{ needs.initialize.outputs.version }}; then
          if [ "${{ env.NEED_DOCKER_LOGIN }}" = "false" ]; then
            echo "::warning::Push failed, trying to login to Docker Hub..."
            echo ${{ secrets.DOCKERHUB_TOKEN }} | docker login -u ${{ secrets.DOCKERHUB_USERNAME }} --password-stdin
            docker push ${DOCKER_REGISTRY}:${{ needs.initialize.outputs.version }}
          else
            echo "::error::Failed to push Docker image"
            exit 1
          fi
        fi
        docker push ${DOCKER_REGISTRY}:latest
        
    - name: Update Last Successful Build
      if: success() && steps.check-changes.outputs.docker_image_built == 'true'
      run: |
        # Update the last successful build hash in permanent storage
        echo "Updating last successful build hash..."
        NEW_HASH=$(git rev-parse HEAD)
        
        # Write hash with atomic operation
        echo "$NEW_HASH" > "${BUILD_METADATA_DIR}/last_successful_build"
        chmod 644 "${BUILD_METADATA_DIR}/last_successful_build"
        
        echo "Successfully updated build hash to: $NEW_HASH"

  test-deploy:
    name: 🧪 Deploy & Verify Test Instance
    needs: [build]
    runs-on: self-hosted
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      with:
        clean: true
        fetch-depth: 0

    - name: Deploy Test Instance
      id: deploy
      run: |
        # Check if new image exists and set version
        if [ "${{ needs.build.outputs.docker_image_built }}" = "true" ]; then
          APP_VERSION="${{ needs.initialize.outputs.version }}"
          echo "Using new build version: $APP_VERSION"
        else
          # Use latest version if no new build
          echo "No new build, using latest version..."
          docker pull ${DOCKER_REGISTRY}:latest
          APP_VERSION="latest"
        fi

        export APP_VERSION
        export APP_DISPLAY_VERSION="${{ needs.initialize.outputs.display_version }}"
        
        # Set up test instance variables
        COMPANY_DIR="virga"
        TEST_DOMAIN="test-${COMPANY_DIR}.${COMPANY_DOMAIN}"
        TEST_INSTANCE_DIR="${INSTANCE_DIR}/test-${COMPANY_DIR}"

        # Check if deploy-instance.sh is executable
        if [ ! -x "./deploy-instance.sh" ]; then
          echo "Making deploy-instance.sh executable..."
          chmod +x ./deploy-instance.sh || sudo -n chmod +x ./deploy-instance.sh || {
            echo "::error::Failed to make deploy-instance.sh executable"
            exit 1
          }
        fi
        
        echo "🚀 Deploying test instance to ${TEST_DOMAIN}..."
        
        ./deploy-instance.sh \
          --company-name="Test ${COMPANY_DIR}" \
          --company-address="Test Address" \
          --company-phone="0123456789" \
          --company-email="test@${COMPANY_DOMAIN}" \
          --domain="${TEST_DOMAIN}" \
          --admin-password="${{ secrets.TEST_ADMIN_PASSWORD }}" \
          --port=3099 \
          --force

        echo "✅ Deployed test instance to ${TEST_DOMAIN}"
          
    - name: Verify Test Instance
      run: |
        COMPANY_DIR="virga"
        TEST_DOMAIN="test-${COMPANY_DIR}.${COMPANY_DOMAIN}"
        echo "🔍 Verifying test instance at ${TEST_DOMAIN}..."
        
        # Wait for instance to be ready
        for i in {1..10}; do
          if curl -sf "https://${TEST_DOMAIN}/health" > /dev/null; then
            echo "✅ Test instance health check passed"

            # Check if remove-instance.sh is executable
            if [ ! -x "./remove-instance.sh" ]; then
              echo "Making remove-instance.sh executable..."
              chmod +x ./remove-instance.sh || sudo -n chmod +x ./remove-instance.sh || {
                echo "::error::Failed to make remove-instance.sh executable"
                exit 1
              }
            fi
            
            # Remove test instance after successful verification
            echo "🧹 Removing test instance..."

            ./remove-instance.sh --company-name="test-${COMPANY_DIR}" --force
            
            echo "✅ Removed test instance"
            exit 0
          fi
          echo "Waiting for instance to be ready... (attempt $i/10)"
          sleep 30
        done
        
        echo "❌ Test instance health check failed after 10 attempts"
        exit 1

  backup:
    name: 📦 Backup Production Databases
    needs: [test-deploy, initialize]
    if: always() && (needs.test-deploy.result == 'success' || needs.test-deploy.result == 'skipped')
    runs-on: self-hosted
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      with:
        clean: true
        fetch-depth: 0

    - name: Backup Production Databases
      run: |
        timestamp=$(date +%Y%m%d)
        version="${{ needs.initialize.outputs.version }}"
        git_sha=$(echo "$version" | cut -d'-' -f3)  # Extract SHA from version string
        IFS=',' read -ra instance_array <<< "${{ needs.initialize.outputs.active_instances }}"
        
        echo "🔄 Processing instance backups..."
        
        # Exit if no instances
        [ -z "${{ needs.initialize.outputs.active_instances }}" ] && echo "No instances to backup" && exit 0
        
        # Process each instance
        for instance in "${instance_array[@]}"; do
          IFS='|' read -r id domain dir <<< "$instance"
          [ -z "$id" ] && continue
          
          echo "📦 Backing up instance: $id ($domain)"
          
          # Create backup directory with git SHA
          backup_dir="${BACKUP_DIR}/${id}/backup_${timestamp}_${git_sha}"
          mkdir -p "$backup_dir" || { echo "Failed to create backup dir for $id"; continue; }
          
          # Backup main database using VACUUM
          if [ -f "${dir}/db/database.sqlite" ]; then
            if ! echo ".backup '${backup_dir}/database.sqlite'" | sqlite3 "${dir}/db/database.sqlite"; then
              echo "Failed to backup database for $id"
              continue
            fi
            echo "✓ Database backed up to: ${backup_dir}/database.sqlite"
          fi
          
          # Copy database for preprod
          preprod_dir="${INSTANCE_DIR}/preprod-${id}"
          mkdir -p "${preprod_dir}/db" || { echo "Failed to create preprod dir for $id"; continue; }
          
          if [ -f "${dir}/db/database.sqlite" ]; then
            if ! echo ".backup '${preprod_dir}/db/database.sqlite'" | sqlite3 "${dir}/db/database.sqlite"; then
              echo "Failed to copy database to preprod for $id"
              continue
            fi
            echo "✓ Database copied to preprod: ${preprod_dir}/db/database.sqlite"
          fi
        done

  deploy-preprod:
    name: 🚀 Deploy PreProduction Instances
    needs: [backup, initialize, build]
    if: always() && (needs.backup.result == 'success' || needs.backup.result == 'skipped')
    runs-on: self-hosted
    environment: preprod
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      with:
        clean: true
        fetch-depth: 0

    - name: Deploy PreProd Instances
      id: deploy
      run: |
        # Set version based on whether we built a new image or not
        if [ "${{ needs.build.outputs.docker_image_built }}" = "true" ]; then
          APP_VERSION="${{ needs.initialize.outputs.version }}"
          echo "Using new build version: $APP_VERSION"
        else
          # Always pull latest image to ensure we have the most recent version
          echo "No new build, using latest version and ensuring it's up to date..."
          docker pull ${DOCKER_REGISTRY}:latest
          APP_VERSION="latest"
        fi
        
        export APP_VERSION
        export APP_DISPLAY_VERSION="${{ needs.initialize.outputs.display_version }}"
        instances="${{ needs.initialize.outputs.active_instances }}"
        
        # Exit if no instances
        [ -z "$instances" ] && echo "No instances to deploy" && exit 0
        
        # Check if deploy-instance.sh is executable
        if [ ! -x "./deploy-instance.sh" ]; then
          echo "Making deploy-instance.sh executable..."
          chmod +x ./deploy-instance.sh || sudo -n chmod +x ./deploy-instance.sh || {
            echo "::error::Failed to make deploy-instance.sh executable"
            exit 1
          }
        fi
        
        # Create deployment report
        report_file="${RUNNER_TEMP}/preprod_deployment.txt"
        echo "PreProduction Deployment Report - $(date)" > "$report_file"
        echo "Using version: $APP_VERSION" >> "$report_file"
        
        # Stop and remove existing preprod containers
        echo "🧹 Cleaning up existing preprod containers..."
        docker ps -q --filter name=preprod-.*-plateform | xargs -r docker stop
        docker ps -aq --filter name=preprod-.*-plateform | xargs -r docker rm
        docker network ls --filter name=preprod-* -q | xargs -r docker network rm
        
        # Track overall success
        overall_success=true
        
        # Process instances
        IFS=',' read -ra instance_array <<< "$instances"
        for instance in "${instance_array[@]}"; do
          IFS='|' read -r id domain dir <<< "$instance"
          [ -z "$id" ] && continue
          
          echo "🔄 Deploying preprod for: $id"
          echo "Instance: $id ($domain)" >> "$report_file"
          
          preprod_domain="preprod-${domain}"
          instance_dir_name="preprod-${id}"
          deployment_success=false
          
          # Find available port
          PORT=3000
          while ss -tulpn | grep ":$PORT" >/dev/null 2>&1; do
            PORT=$((PORT + 1))
            if [ $PORT -gt 3100 ]; then
              echo "::error::No available ports found in range 3000-3100"
              exit 1
            fi
          done
          echo "Found available port: $PORT"

          if [[ ! -x "./deploy-instance.sh" ]]; then
            echo "Making deploy-instance.sh executable..."
            chmod +x ./deploy-instance.sh || sudo -n chmod +x ./deploy-instance.sh || {
              echo "::error::Failed to make deploy-instance.sh executable"
              exit 1
            }
          fi
          
          # Always deploy new instance regardless of build status
          ./deploy-instance.sh \
            --company-name="PreProd-${id}" \
            --company-address="PreProd Environment" \
            --company-phone="0123456789" \
            --company-email="preprod@${COMPANY_DOMAIN}" \
            --domain="${preprod_domain}" \
            --admin-password="${{ secrets.TEST_ADMIN_PASSWORD }}" \
            --port=$PORT \
            --force && deployment_success=true
          
          if [ "$deployment_success" = true ]; then
            echo "✓ Deployed: ${preprod_domain}" >> "$report_file"
            
            # Verify deployment
            health_check_success=false
            for i in {1..5}; do
              if curl -sf "https://${preprod_domain}/health" > /dev/null; then
                echo "✓ Health check passed" >> "$report_file"
                health_check_success=true
                break
              fi
              if [ $i -eq 5 ]; then
                echo "✗ Health check failed after 5 attempts" >> "$report_file"
                overall_success=false
              else
                echo "Retrying health check... (attempt $i/5)"
                sleep 30
              fi
            done
          else
            echo "✗ Deployment failed" >> "$report_file"
            overall_success=false
          fi
          
          echo "---" >> "$report_file"
        done
        
        # Save report
        mkdir -p "${GITHUB_WORKSPACE}/reports"
        cp "$report_file" "${GITHUB_WORKSPACE}/reports/preprod_$(date +%Y%m%d_%H%M%S).txt"
        
        # Exit with failure if any deployment failed
        $overall_success || exit 1

    - name: Verify Deployment Status
      id: verify
      run: |
        # Exit if no instances
        [ -z "${{ needs.initialize.outputs.active_instances }}" ] && exit 0
        
        # Track verification status
        verification_failed=false
        
        # Verify each instance
        IFS=',' read -ra instance_array <<< "${{ needs.initialize.outputs.active_instances }}"
        for instance in "${instance_array[@]}"; do
          IFS='|' read -r id domain dir <<< "$instance"
          [ -z "$id" ] && continue
          preprod_domain="preprod-${domain}"
          preprod_dir="${INSTANCE_DIR}/preprod-${id}"
          
          echo "🔍 Verifying $preprod_domain..."
          
          # Verify database exists and is valid
          if [ ! -f "${preprod_dir}/db/database.sqlite" ]; then
            echo "❌ Database file missing for $preprod_domain"
            verification_failed=true
            continue
          fi
          
          # Verify database integrity
          if ! echo "PRAGMA integrity_check;" | sqlite3 "${preprod_dir}/db/database.sqlite" > /dev/null; then
            echo "❌ Database integrity check failed for $preprod_domain"
            verification_failed=true
            continue
          fi
          
          # Check if instance is accessible and healthy
          health_check_success=false
          for i in {1..5}; do
            if curl -sf "https://${preprod_domain}/health" > /dev/null; then
              echo "✅ $preprod_domain is healthy"
              health_check_success=true
              break
            fi
            if [ $i -eq 5 ]; then
              echo "❌ $preprod_domain health check failed"
              verification_failed=true
            else
              echo "Retrying health check... (attempt $i/5)"
              sleep 30
            fi
          done
          
          # Verify container is running
          if ! docker ps --format '{{.Names}}' | grep -q "^preprod-${id}-plateform$"; then
            echo "❌ Container not running for $preprod_domain"
            verification_failed=true
          fi
          
        done <<< "${{ needs.initialize.outputs.active_instances }}"
        
        if [ "$verification_failed" = true ]; then
          echo "::error::One or more preprod instances failed verification"
          exit 1
        fi
        
        echo "✅ All preprod instances verified successfully"

  deploy-production:
    name: 🚀 Deploy Production Instances
    needs: [deploy-preprod, initialize]
    environment: production
    runs-on: self-hosted
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      with:
        clean: true
        fetch-depth: 0

    - name: Create Rollback Point
      id: rollback
      run: |
        timestamp=$(date +%Y%m%d_%H%M%S)
        version="${{ needs.initialize.outputs.version }}"
        rollback_dir="${BACKUP_DIR}/rollback_${timestamp}_${version}"
        
        # Ensure backup directory exists and is writable
        if ! mkdir -p "$rollback_dir"; then
          echo "::error::Failed to create rollback directory"
          exit 1
        fi
        
        echo "timestamp=${timestamp}" >> $GITHUB_OUTPUT
        echo "rollback_dir=${rollback_dir}" >> $GITHUB_OUTPUT
        
        # Track backup status
        backup_failed=false
        failed_backups=()
        
        # Function to get file size that works on both Linux and BSD
        get_file_size() {
          if [ -f "$1" ]; then
            if stat --version >/dev/null 2>&1; then
              # GNU stat
              stat -c%s "$1"
            else
              # BSD stat
              stat -f%z "$1"
            fi
          else
            echo "0"
          fi
        }
        
        # Save current state of each instance
        while IFS='|' read -r id domain dir; do
          [ -z "$id" ] && continue
          
          instance_backup="${rollback_dir}/${id}"
          if ! mkdir -p "${instance_backup}/db"; then
            echo "::error::Failed to create backup directory for $id"
            backup_failed=true
            failed_backups+=("$id")
            continue
          fi
          
          echo "📦 Creating rollback point for $id..."
          
          # Backup database with verification
          if [ -f "${dir}/db/database.sqlite" ]; then
            # Check if database is not corrupted
            if ! echo "PRAGMA integrity_check;" | sqlite3 "${dir}/db/database.sqlite"; then
              echo "::error::Database corruption detected for $id"
              backup_failed=true
              failed_backups+=("$id")
              continue
            fi
            
            # Create backup with VACUUM
            if ! echo ".backup '${instance_backup}/db/database.sqlite'" | sqlite3 "${dir}/db/database.sqlite"; then
              echo "::error::Failed to create database backup for $id"
              backup_failed=true
              failed_backups+=("$id")
              continue
            fi
            
            # Verify backup
            if ! echo "PRAGMA integrity_check;" | sqlite3 "${instance_backup}/db/database.sqlite"; then
              echo "::error::Backup verification failed for $id"
              backup_failed=true
              failed_backups+=("$id")
              continue
            fi
            
            # Check backup size using the portable function
            original_size=$(get_file_size "${dir}/db/database.sqlite")
            backup_size=$(get_file_size "${instance_backup}/db/database.sqlite")
            if [ "$backup_size" -lt "$((original_size / 2))" ]; then
              echo "::error::Backup size verification failed for $id (original: ${original_size}, backup: ${backup_size})"
              backup_failed=true
              failed_backups+=("$id")
              continue
            fi
          fi
          
          # Save current container state with timeout
          if docker ps --format '{{.Names}}' | grep -q "^${id}-plateform$"; then
            timeout 30s docker inspect "${id}-plateform" > "${instance_backup}/container_state.json" || {
              echo "::error::Failed to save container state for $id"
              backup_failed=true
              failed_backups+=("$id")
              continue
            }
          fi
          
          # Save environment files with verification
          if [ -f "${dir}/secrets.env" ]; then
            if ! cp "${dir}/secrets.env" "${instance_backup}/"; then
              echo "::error::Failed to backup secrets for $id"
              backup_failed=true
              failed_backups+=("$id")
              continue
            fi
            
            # Verify copy
            if ! diff "${dir}/secrets.env" "${instance_backup}/secrets.env" >/dev/null; then
              echo "::error::Secrets backup verification failed for $id"
              backup_failed=true
              failed_backups+=("$id")
              continue
            fi
          fi
          
          echo "✅ Rollback point created for $id"
        done <<< "${{ needs.initialize.outputs.active_instances }}"
        
        # Save backup status
        echo "backup_failed=${backup_failed}" >> $GITHUB_OUTPUT
        echo "failed_backups=${failed_backups[*]}" >> $GITHUB_OUTPUT
        
        if [ "$backup_failed" = true ]; then
          echo "::error::Failed to create rollback points for: ${failed_backups[*]}"
          exit 1
        fi

    - name: Deploy to Production
      id: deploy
      run: |
        export APP_VERSION="${{ needs.initialize.outputs.version }}"
        instances="${{ needs.initialize.outputs.active_instances }}"
        rollback_dir="${{ steps.rollback.outputs.rollback_dir }}"
        
        # Exit if no instances
        [ -z "$instances" ] && echo "No instances to deploy" && exit 0
        
        # Check if deploy-instance.sh is executable
        if [ ! -x "./deploy-instance.sh" ]; then
          echo "Making deploy-instance.sh executable..."
          chmod +x ./deploy-instance.sh || sudo -n chmod +x ./deploy-instance.sh || {
            echo "::error::Failed to make deploy-instance.sh executable"
            exit 1
          }
        fi
        
        # Create deployment report
        report_file="${RUNNER_TEMP}/production_deployment.txt"
        echo "Production Deployment Report - $(date)" > "$report_file"
        
        # Track deployment status
        deployment_failed=false
        failed_instances=()
        
        echo "🚀 Starting production deployment..."
        IFS=',' read -ra instance_array <<< "$instances"
        for instance_data in "${instance_array[@]}"; do
          IFS='|' read -r id domain dir <<< "$instance_data"
          [ -z "$id" ] && continue
          
          echo "Deploying $id ($domain)..."
          echo "Instance: $id ($domain)" >> "$report_file"
          
          if ./deploy-instance.sh \
            --company-name="${id}" \
            --domain="${domain}" \
            --force \
            --update-only; then
            echo "✅ Deployed successfully" >> "$report_file"
            
            # Verify deployment
            for i in {1..5}; do
              if curl -sf "https://${domain}/health" > /dev/null; then
                echo "✅ $id deployed successfully"
                echo "✅ Health check passed" >> "$report_file"
                break
              fi
              if [ $i -eq 5 ]; then
                echo "❌ Health check failed for $id"
                echo "❌ Health check failed" >> "$report_file"
                deployment_failed=true
                failed_instances+=("$id")
              else
                sleep 30
              fi
            done
          else
            echo "❌ Deployment failed for $id"
            echo "❌ Deployment failed" >> "$report_file"
            deployment_failed=true
            failed_instances+=("$id")
          fi
          
          echo "---" >> "$report_file"
        done
        
        # Save deployment status for potential rollback
        echo "deployment_failed=${deployment_failed}" >> $GITHUB_OUTPUT
        echo "failed_instances=${failed_instances[*]}" >> $GITHUB_OUTPUT
        
        # Save report
        mkdir -p "${GITHUB_WORKSPACE}/reports"
        cp "$report_file" "${GITHUB_WORKSPACE}/reports/production_$(date +%Y%m%d_%H%M%S).txt"
        
        if [ "$deployment_failed" = true ]; then
          echo "::error::Deployment failed for instances: ${failed_instances[*]}"
          exit 1
        fi

    - name: Verify Production Deployment
      id: verify
      run: |
        if [ "${{ steps.deploy.outputs.deployment_failed }}" = "true" ]; then
          echo "::error::Production deployment failed for instances: ${{ steps.deploy.outputs.failed_instances }}"
          exit 1
        fi
        echo "✅ Production deployment verified successfully"

    - name: Rollback Failed Deployments
      if: failure() && steps.deploy.outputs.deployment_failed == 'true'
      run: |
        echo "🔄 Starting rollback procedure..."
        rollback_dir="${{ steps.rollback.outputs.rollback_dir }}"
        failed_instances="${{ steps.deploy.outputs.failed_instances }}"
        instances="${{ needs.initialize.outputs.active_instances }}"
        
        # Debug information
        echo "Debug Information:"
        echo "Rollback directory: $rollback_dir"
        echo "Failed instances: $failed_instances"
        echo "All instances: $instances"
        
        # Track rollback status
        rollback_failed=false
        rollback_report=""
        
        # Convert failed_instances to array for better handling
        IFS=' ' read -ra failed_array <<< "$failed_instances"
        echo "Failed instances array: ${failed_array[*]}"
        
        # Split instances by comma and process each
        IFS=',' read -ra instance_array <<< "$instances"
        for instance_data in "${instance_array[@]}"; do
          IFS='|' read -r id domain dir <<< "$instance_data"
          [ -z "$id" ] && continue
          
          # Improved check for failed instances
          needs_rollback=false
          for failed_id in "${failed_array[@]}"; do
            if [ "$failed_id" = "$id" ]; then
              needs_rollback=true
              break
            fi
          done
          
          if [ "$needs_rollback" = false ]; then
            echo "Skipping $id - not in failed instances list"
            continue
          fi
          
          echo "📦 Rolling back instance: $id ($domain)"
          instance_backup="${rollback_dir}/${id}"
          rollback_log="${RUNNER_TEMP}/rollback_${id}.log"
          
          # Initialize rollback log with debug information
          {
            echo "Rollback Log for $id ($domain)"
            echo "Timestamp: $(date)"
            echo "Backup Directory: $instance_backup"
            echo "Failed Instances: $failed_instances"
            echo "Instance Directory: $dir"
          } > "$rollback_log"
          
          # Verify backup directory structure
          echo "Checking backup directory structure:" >> "$rollback_log"
          if [ -d "$rollback_dir" ]; then
            ls -la "$rollback_dir" >> "$rollback_log" 2>&1
          else
            echo "Parent rollback directory not found: $rollback_dir" >> "$rollback_log"
          fi
          
          if [ ! -d "$instance_backup" ]; then
            echo "::error::Rollback data not found for $id at $instance_backup"
            echo "❌ Backup directory not found" >> "$rollback_log"
            echo "Parent directory contents:" >> "$rollback_log"
            ls -la "$rollback_dir" >> "$rollback_log" 2>&1
            rollback_failed=true
            rollback_report+="❌ $id: Backup data not found\n"
            continue
          fi
          
          # Log backup contents
          echo "📝 Backup contents:" >> "$rollback_log"
          ls -la "$instance_backup" >> "$rollback_log" 2>&1
          
          # Stop current container with timeout and force if needed
          echo "🛑 Stopping current container..." >> "$rollback_log"
          if timeout 30s docker stop "${id}-plateform"; then
            echo "✅ Container stopped gracefully" >> "$rollback_log"
          else
            echo "⚠️ Force stopping container..." >> "$rollback_log"
            docker kill "${id}-plateform" || true
          fi
          docker rm "${id}-plateform" || true
          
          # Restore database with verification
          if [ -f "${instance_backup}/db/database.sqlite" ]; then
            echo "🔄 Restoring database..." >> "$rollback_log"
            
            # Verify backup integrity
            if ! echo "PRAGMA integrity_check;" | sqlite3 "${instance_backup}/db/database.sqlite"; then
              echo "::error::Backup corruption detected for $id, skipping restore"
              echo "❌ Backup database is corrupted" >> "$rollback_log"
              rollback_failed=true
              rollback_report+="❌ $id: Database backup corrupted\n"
              continue
            fi
            
            # Create restore directory if needed
            restore_dir="${INSTANCE_DIR}/${id}/db"
            mkdir -p "$restore_dir"
            
            # Backup current database before restore
            if [ -f "${restore_dir}/database.sqlite" ]; then
              cp "${restore_dir}/database.sqlite" "${restore_dir}/database.sqlite.failed_deploy"
              echo "✅ Created backup of failed deployment database" >> "$rollback_log"
            fi
            
            # Restore with verification
            if ! cp "${instance_backup}/db/database.sqlite" "${restore_dir}/database.sqlite"; then
              echo "::error::Failed to restore database for $id"
              echo "❌ Database restore failed" >> "$rollback_log"
              rollback_failed=true
              rollback_report+="❌ $id: Database restore failed\n"
              continue
            fi
            
            # Verify restored database
            if ! echo "PRAGMA integrity_check;" | sqlite3 "${restore_dir}/database.sqlite"; then
              echo "::error::Restored database verification failed for $id"
              echo "❌ Restored database verification failed" >> "$rollback_log"
              rollback_failed=true
              rollback_report+="❌ $id: Database verification failed\n"
              continue
            fi
            
            echo "✅ Database restored and verified" >> "$rollback_log"
          fi
          
          # Restore environment files with verification
          if [ -f "${instance_backup}/secrets.env" ]; then
            echo "🔄 Restoring environment files..." >> "$rollback_log"
            if ! cp "${instance_backup}/secrets.env" "${INSTANCE_DIR}/${id}/secrets.env"; then
              echo "::error::Failed to restore secrets for $id"
              echo "❌ Failed to restore secrets" >> "$rollback_log"
              rollback_failed=true
              rollback_report+="❌ $id: Secrets restore failed\n"
              continue
            fi
            echo "✅ Environment files restored" >> "$rollback_log"
          fi
          
          # Restore container from previous state
          if [ -f "${instance_backup}/container_state.json" ]; then
            echo "🔄 Restoring container..." >> "$rollback_log"
            # Parse version using grep and sed instead of jq
            previous_version=$(grep -o '"version":"[^"]*"' "${instance_backup}/container_state.json" | sed 's/"version":"\(.*\)"/\1/')
            if [ ! -z "$previous_version" ]; then
              echo "📦 Using previous version: $previous_version" >> "$rollback_log"
              export APP_VERSION="$previous_version"
              
              # Make deploy script executable if needed
              if [ ! -x "./deploy-instance.sh" ]; then
                chmod +x ./deploy-instance.sh || sudo chmod +x ./deploy-instance.sh
              fi
              
              if ! ./deploy-instance.sh \
                --company-name="${id}" \
                --domain="${domain}" \
                --force \
                --update-only 2>> "$rollback_log"; then
                echo "::error::Failed to restore container for $id"
                echo "❌ Container restore failed" >> "$rollback_log"
                rollback_failed=true
                rollback_report+="❌ $id: Container restore failed\n"
                continue
              fi
              
              # Verify container is running
              sleep 10
              if ! docker ps --format '{{.Names}}' | grep -q "^${id}-plateform$"; then
                echo "::error::Restored container is not running for $id"
                echo "❌ Container not running after restore" >> "$rollback_log"
                rollback_failed=true
                rollback_report+="❌ $id: Container not running\n"
                continue
              fi
              echo "✅ Container restored and running" >> "$rollback_log"
            else
              echo "⚠️ No previous version found in container state" >> "$rollback_log"
            fi
          fi
          
          # Verify rollback with extended health checks
          echo "🔍 Verifying rollback..." >> "$rollback_log"
          health_check_success=false
          for i in {1..10}; do
            if curl -sf "https://${domain}/health" > /dev/null; then
              echo "✅ Health check passed on attempt $i" >> "$rollback_log"
              health_check_success=true
              break
            fi
            if [ $i -eq 10 ]; then
              echo "::error::Rollback verification failed for $id after 10 attempts"
              echo "❌ Health check failed after 10 attempts" >> "$rollback_log"
              rollback_failed=true
              rollback_report+="❌ $id: Health check failed\n"
            else
              echo "⏳ Retry $i/10: Waiting for service to be healthy..." >> "$rollback_log"
              sleep 30
            fi
          done
          
          if [ "$health_check_success" = true ]; then
            echo "✅ Rollback successful for $id" >> "$rollback_log"
            rollback_report+="✅ $id: Rollback successful\n"
          fi
          
          # Save rollback log
          mkdir -p "${GITHUB_WORKSPACE}/reports"
          cp "$rollback_log" "${GITHUB_WORKSPACE}/reports/rollback_${id}_$(date +%Y%m%d_%H%M%S).txt"
        done
        
        # Print final rollback report
        echo -e "\n📋 Rollback Report:"
        echo -e "$rollback_report"
        
        if [ "$rollback_failed" = true ]; then
          echo "::error::One or more rollbacks failed. Check the reports directory for detailed logs."
          exit 1
        fi

  cleanup:
    name: 🧹 Cleanup and Maintenance
    needs: [deploy-production]
    if: always()
    runs-on: self-hosted
    
    steps:
    - name: Cleanup Old Backups
      run: |
        # Ensure we're in the correct directory
        if [ ! -d "${BACKUP_DIR}" ]; then
          echo "::error::Backup directory not found"
          exit 1
        fi
        
        # Create a temporary directory for atomic operations
        temp_dir=$(mktemp -d)
        trap 'rm -rf "$temp_dir"' EXIT
        
        echo "🧹 Cleaning up old backups..."
        
        # Process each instance directory
        find "${BACKUP_DIR}" -mindepth 1 -maxdepth 1 -type d | while read instance_dir; do
          if [[ "$instance_dir" != *"/rollback_"* ]]; then
            # Ensure we can access the directory
            if [ ! -r "$instance_dir" ] || [ ! -w "$instance_dir" ]; then
              echo "::warning::Cannot access directory: $instance_dir"
              continue
            fi
            
            cd "$instance_dir" || continue
            
            # List files to delete before removing them
            ls -t | tail -n +9 > "$temp_dir/to_delete.txt"
            
            # Remove files if list is not empty
            if [ -s "$temp_dir/to_delete.txt" ]; then
              while read -r file; do
                rm -rf "$file"
              done < "$temp_dir/to_delete.txt"
            fi
          fi
        done
        
        # Clean up rollback points
        cd "${BACKUP_DIR}" || exit 1
        ls -td rollback_* 2>/dev/null | tail -n +3 | while read -r rollback; do
          rm -rf "$rollback"
        done
        
        echo "✅ Backup cleanup completed"

    - name: Cleanup PreProd Instances
      if: needs.deploy-production.result == 'success'
      run: |
        echo "🧹 Cleaning up successful preprod instances..."
        
        # Stop containers with timeout and error handling
        docker ps -q --filter name=preprod-.*-plateform | while read -r container; do
          if ! timeout 30s docker stop "$container"; then
            echo "::warning::Failed to stop container: $container"
            docker kill "$container" || true
          fi
        done
        
        # Remove stopped containers
        docker ps -aq --filter name=preprod-.*-plateform | while read -r container; do
          timeout 30s docker rm "$container" || true
        done
        
        # Clean up networks safely
        docker network ls --filter name=preprod-* -q | while read -r network; do
          timeout 30s docker network rm "$network" || true
        done
        
        # Remove old preprod databases with verification
        find "${INSTANCE_DIR}" -name "preprod-*" -type d -mtime +7 | while read -r dir; do
          if [ -d "$dir" ]; then
            # Ensure no containers are using this directory
            if ! lsof "$dir" >/dev/null 2>&1; then
              rm -rf "$dir"
            else
              echo "::warning::Directory in use, skipping: $dir"
            fi
          fi
        done
        
        echo "✅ Cleanup completed"

    - name: Generate Final Report
      run: |
        echo "## 📊 Deployment Summary" > final_report.md
        echo "Version: ${{ needs.initialize.outputs.display_version }}" >> final_report.md
        echo "Technical version: ${{ needs.initialize.outputs.version }}" >> final_report.md
        echo "" >> final_report.md
        
        if [ "${{ needs.deploy-production.result }}" = "success" ]; then
          echo "### ✅ Deployment Pipeline Complete" >> final_report.md
          echo "- All instances deployed successfully" >> final_report.md
          echo "- Backups created and verified" >> final_report.md
          echo "- Old backups cleaned up" >> final_report.md
          echo "- PreProd instances cleaned up" >> final_report.md
        else
          echo "### ❌ Deployment Pipeline Failed" >> final_report.md
          echo "- Check deployment reports for error details" >> final_report.md
          echo "- Rollback procedures executed for failed instances" >> final_report.md
          echo "- PreProd instances preserved for debugging" >> final_report.md
        fi
        
        cat final_report.md